{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lineal regressions in higher dimension:\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Time elapsed was: 0.031159\n",
      "Training error: 0.258185\n",
      "Testing error: 0.259617\n",
      "\n",
      "Newton method:\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "Time elapsed was: 0.138572\n",
      "Training error: 0.258185\n",
      "Testing error: 0.259617\n",
      "\n",
      "Gaussian kernel:\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (2250,2) not aligned: 2 (dim 0) != 2250 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c6e10f76267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;31m#print(gaussian(r[0],r[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mvar-set1.dat.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9c6e10f76267>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gaussian kernel:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Time elapsed was: %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9c6e10f76267>\u001b[0m in \u001b[0;36mcross_validation_gaussian\u001b[0;34m(x, y, k)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mtraine\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mteste\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mtraine\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9c6e10f76267>\u001b[0m in \u001b[0;36mcompute_error\u001b[0;34m(x, y, t, d, gauss)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0m_yhat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0m_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9c6e10f76267>\u001b[0m in \u001b[0;36myhat\u001b[0;34m(x, t, d, gauss)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgauss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (2250,2) not aligned: 2 (dim 0) != 2250 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pylab import *\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import time\n",
    "\n",
    "#\n",
    "#This function loads a file with the name given into to np arrays x and y.\n",
    "#Parameters: Name of the file to load\n",
    "#Returns: nparray x with feature information and nparray y with label information\n",
    "def load_file(name):\n",
    "    file = open(name,'r')\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for line in file:\n",
    "        if not line.startswith('#'):\n",
    "            l=line.split()\n",
    "            xi=[]\n",
    "            for i in range(0,len(l)-1):\n",
    "                xi.append(float(l[i]))\n",
    "            x.append(xi)\n",
    "            y.append(float(l[len(l)-1]))\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "#This function calculates y-hat given x values, theta values and a degree.\n",
    "#Parameters: x - matrix or vector, t - theta vector, d - degree\n",
    "#Returns: y-hat vector\n",
    "def yhat(x,t,d=1,gauss=False):\n",
    "    print(gauss)\n",
    "    if gauss:\n",
    "        return dot(x,t.T)\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    if(x.shape[1]>x.shape[0]):\n",
    "        x=np.transpose(x)\n",
    "    x=poly.fit_transform(x)\n",
    "    return dot(x,t)\n",
    "\n",
    "#This function regresses the data to find the polynomial model given a degree\n",
    "#Parameters: x - vector or matrix, y - vector, d - degree of polynomial, two by default\n",
    "#Returns: theta vector\n",
    "def poly_reg(x,y,d=2):\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    z = poly.fit_transform(x)\n",
    "    a = dot(dot(inv(dot(z.T,z)),z.T),y)\n",
    "    return a\n",
    "\n",
    "#This is the iterative method to find \n",
    "def newton_method(x,y,d=2):\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    Z=poly.fit_transform(x)\n",
    "    theta=np.ones(Z.shape[1])\n",
    "    theta=theta.reshape(len(theta),1)\n",
    "    diff = 1\n",
    "    while(diff > 1e-15):\n",
    "    #for i in range (0,50):\n",
    "        theta_i=theta\n",
    "        theta = calc_theta(theta_i,Z,y)\n",
    "        diff=np.absolute(theta_i-theta)\n",
    "        diff=(np.average(diff))\n",
    "    return theta\n",
    "        \n",
    "    \n",
    "def calc_theta(t,Z,y):\n",
    "    y=y.reshape(len(y),1)\n",
    "    y_hat = np.dot(Z,t)\n",
    "    ret = np.subtract(y_hat,y)\n",
    "    ret = np.dot(np.transpose(Z),ret)\n",
    "    h = np.dot(np.transpose(Z),Z)\n",
    "    h = inv(h)\n",
    "    ret = np.dot(h,ret)\n",
    "    ret = t-ret\n",
    "    return ret\n",
    "\n",
    "#\n",
    "#This function computes the MSE error given data and a theta vector\n",
    "#Parameters: x - vector or matrix, y - vector, t - theta vector, d - degree of polynomial, one by default,\n",
    "#gauss - determines wether the function to be analized is gaussian.\n",
    "#Returns: MSE \n",
    "def compute_error(x,y,t,d=1,gauss=False):\n",
    "    print(gauss)\n",
    "    total =0\n",
    "    _yhat=(yhat(x,t,d,gauss))\n",
    "    for i in range(0,len(x)):\n",
    "        total+=(((y[i]-_yhat[i])**2))\n",
    "    total/=len(x)\n",
    "    return total\n",
    "\n",
    "#\n",
    "#This function performs crossvalidation to find the average training and testing MSE's of\n",
    "#given data using polynomial function, given a degree and a k-factor.\n",
    "#Parameters: x - vector or matrix, y - vector, k - integer, d - degree, integer.\n",
    "#Returns: training and testing MSE's\n",
    "def cross_validation_multi(x,y,k=10,d=2):\n",
    "    traine=0\n",
    "    teste=0\n",
    "    kf = KFold(x.shape[0],k)\n",
    "    for train, test in kf:\n",
    "        t = poly_reg(x[train],y[train],d)\n",
    "        traine+=compute_error(x[train],y[train],t,d)\n",
    "        teste += compute_error(x[test],y[test],t,d)\n",
    "    traine/=k\n",
    "    teste/=k\n",
    "    \n",
    "    return traine, teste\n",
    "\n",
    "#\n",
    "#This function performs crossvalidation to find the average training and testing MSE's of\n",
    "#given data using the newton function, given a degree and a k-factor.\n",
    "#Parameters: x - vector or matrix, y - vector, k - integer, d - degree, integer.\n",
    "#Returns: training and testing MSE's\n",
    "def cross_validation_newton(x,y,k=10,d=2):\n",
    "    traine=0\n",
    "    teste=0\n",
    "    kf = KFold(x.shape[0],k)\n",
    "    for train, test in kf:\n",
    "        t = newton_method(x[train],y[train],d)\n",
    "        traine+=compute_error(x[train],y[train],t,d)\n",
    "        teste += compute_error(x[test],y[test],t,d)\n",
    "    traine/=k\n",
    "    teste/=k\n",
    "    \n",
    "    return traine, teste\n",
    "\n",
    "#\n",
    "#This function performs crossvalidation to find the average training and testing MSE's of\n",
    "#given data using gaussian function, given a degree and a k-factor.\n",
    "#Parameters: x - vector or matrix, y - vector, k - integer, d - degree, integer.\n",
    "#Returns: training and testing MSE's\n",
    "def cross_validation_gaussian(x,y,k=10):\n",
    "    traine=0\n",
    "    teste=0\n",
    "    kf = KFold(x.shape[0],k)\n",
    "    for train, test in kf:\n",
    "        t = gaussian(x[train],y[train])\n",
    "        t=t.T\n",
    "        traine+=compute_error(x[train],y[train],t,gauss=True)\n",
    "        teste +=compute_error(x[test],y[test],t,gauss=True)\n",
    "    traine/=k\n",
    "    teste/=k\n",
    "    \n",
    "    return traine, teste\n",
    "\n",
    "#\n",
    "#This function calculates the g matrix iterating through thetas\n",
    "#Parameters: x - matrix\n",
    "#Returns: g matrix\n",
    "def calculate_g(x):\n",
    "    row,col=x.shape\n",
    "    g=np.ones((row,row))\n",
    "    sigma=0.5\n",
    "    for r in range(0,row):\n",
    "        for c in range(0,row):\n",
    "            g[r][c]=np.exp(-np.linalg.norm(x[r,:]-x[c,:])**2/2*sigma**2)\n",
    "    return g\n",
    "\n",
    "#\n",
    "#This function calculates alpha as the dot product of g and y\n",
    "#Parameters: g- matrix, y - vector\n",
    "#Returns: alpha vector\n",
    "def calculate_alpha(g,y):\n",
    "    return dot(inv(g),y)\n",
    "\n",
    "#This method calculates the theta coefficients with the gaussian kernel method.\n",
    "#Parameters: x - matrix, y - vector\n",
    "#Returns: theta vector\n",
    "def gaussian(x,y):\n",
    "    g = calculate_g(x)\n",
    "    alpha = calculate_alpha(g,y)\n",
    "    theta = np.dot(np.transpose(alpha),x)\n",
    "    return theta\n",
    "    \n",
    "    \n",
    "#\n",
    "#This function runs the program according to the given parameters, and prints all necessary\n",
    "#results required from the homework.\n",
    "#Parameters: name - name of file being analized\n",
    "def run(name):\n",
    "    arr=load_file(name)\n",
    "    x,y=arr\n",
    "    print(\"Lineal regressions in higher dimension:\")\n",
    "    start = time.time()\n",
    "    c = cross_validation_multi(x,y)\n",
    "    end = time.time()\n",
    "    print (\"Time elapsed was: %f\"%(end-start))\n",
    "    print (\"Training error: %f\\nTesting error: %f\\n\"%(c[0],c[1]))\n",
    "    \n",
    "    print(\"Newton method:\")\n",
    "    start = time.time()\n",
    "    c = cross_validation_newton(x,y)\n",
    "    end = time.time()\n",
    "    print (\"Time elapsed was: %f\"%(end-start))\n",
    "    print (\"Training error: %f\\nTesting error: %f\\n\"%(c[0],c[1]))\n",
    "    \n",
    "    print(\"Gaussian kernel:\")\n",
    "    start = time.time()\n",
    "    c = cross_validation_gaussian(x,y)\n",
    "    end = time.time()\n",
    "    print (\"Time elapsed was: %f\"%(end-start))\n",
    "    print (\"Training error: %f\\nTesting error: %f\\n\"%(c[0],c[1]))\n",
    "\n",
    "r=load_file(\"mvar-set1.dat.txt\")\n",
    "#print (newton_method(r[0],r[1],2))\n",
    "a = np.arange(20).reshape((5,4))\n",
    "#print(calculate_g(r[0]))\n",
    "#print(a[:,[0,1]])\n",
    "#print ((r[0]))\n",
    "#print ((r[1]))\n",
    "#print(poly_reg(r[0],r[1],2))\n",
    "#print(gaussian(r[0],r[1]))\n",
    "\n",
    "run(\"mvar-set1.dat.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
